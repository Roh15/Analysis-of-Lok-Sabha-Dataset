{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "hindi_ner.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "r5m0qW3ruP97"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfxogBeCwypC",
        "outputId": "0edac82d-349a-42be-c22c-0e5eb8360db3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux50Hr-ruK9s"
      },
      "source": [
        "https://github.com/flairNLP/flair\n",
        "\n",
        "https://medium.com/thecyphy/training-custom-ner-model-using-flair-df1f9ea9c762"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5m0qW3ruP97"
      },
      "source": [
        "# installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJEv5I_KuMiJ",
        "outputId": "f17a4215-51c7-4253-dadd-92437c58a1ce"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.9-py3-none-any.whl (319 kB)\n",
            "\u001b[K     |████████████████████████████████| 319 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting conllu>=4.0\n",
            "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 42.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.9.0+cu111)\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 38.1 MB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting more-itertools~=8.8.0\n",
            "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting gdown==3.12.2\n",
            "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.19.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.6.3)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 868 kB/s \n",
            "\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 34.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 43.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Building wheels for collected packages: gdown, mpld3, overrides, segtok, sqlitedict, ftfy, langdetect, wikipedia-api\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9704 sha256=deedabd5b356aaed9912779ba3571b77a125fbf8b62322ebb770275a48bd1c53\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=c064fcb93a7bc52ab653932f417c34773d39e218b652ffdba8d748e99b6dc86d\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10186 sha256=3f0079e9358b03433180599ee3630ecea1f41c60c3fe9767d06686a00bdd5fa3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=38f8eeb83bba06bbdaa064e9a7d3b6ee8b4cba9813b109cb25da488c297b3bcf\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=900a90e595d0e44efc7181e335420983e8f5aceb68dc74e97533e422ad2dfd11\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=bac1429d4bc78a49276e497e464a42a40ec10d3c38e2e7f2cf10a6654683e673\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=9c9ced228438518ed2f3af8a6e68f52a0617ceb681e2cfbf7a09659c14caa64d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13475 sha256=d9698e1b61083e96a4a85ae864df9cbcb23f45c609a1f964dd2fdac57b45245c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built gdown mpld3 overrides segtok sqlitedict ftfy langdetect wikipedia-api\n",
            "Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, sacremoses, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, mpld3, more-itertools, langdetect, konoha, janome, gdown, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.8.1\n",
            "    Uninstalling importlib-metadata-4.8.1:\n",
            "      Successfully uninstalled importlib-metadata-4.8.1\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 8.10.0\n",
            "    Uninstalling more-itertools-8.10.0:\n",
            "      Successfully uninstalled more-itertools-8.10.0\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.4.1 deprecated-1.2.13 flair-0.9 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.0.19 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 pyyaml-6.0 requests-2.26.0 sacremoses-0.0.46 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 transformers-4.11.3 wikipedia-api-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsq2eT73uS_M"
      },
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeP-yY0A13kb",
        "outputId": "661fb99b-4e8a-47fe-fb3b-b35335e0c55a"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/hindi_ner/'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='hindi_train.txt',\n",
        "                              test_file='hindi_test.txt',\n",
        "                              dev_file='hindi_dev.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-20 18:26:11,304 Reading data from /content/drive/MyDrive/hindi_ner\n",
            "2021-10-20 18:26:11,310 Train: /content/drive/MyDrive/hindi_ner/hindi_train.txt\n",
            "2021-10-20 18:26:11,313 Dev: /content/drive/MyDrive/hindi_ner/hindi_dev.txt\n",
            "2021-10-20 18:26:11,314 Test: /content/drive/MyDrive/hindi_ner/hindi_test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nD8zGx87S2F",
        "outputId": "5240cf20-4ae8-4126-d548-1c9c42dd2ea1"
      },
      "source": [
        "len(corpus.train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15319"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X6bXw3U7HVa",
        "outputId": "bc158e66-e46b-48a8-ec08-ad92758049d7"
      },
      "source": [
        "# create tag dictionary for a ner task\n",
        "ner_dictionary = corpus.make_tag_dictionary('ner')\n",
        "\n",
        "# print dictionary\n",
        "print(ner_dictionary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary with 31 tags: O, NN, JJ, SYM, VM, VAUX, QC, NNP, CC, XC, PSP, DEM, QF, PRP, RP, RDP, NST, QO, RB, PSP:?, INTF, RP:?, NEG, WQ, INJ, CC:?, B-NP, RB:?, XCएंड, <START>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aW16Q9fuK-F"
      },
      "source": [
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# 1. get the corpus\n",
        "print(corpus)\n",
        "\n",
        "# 2. what label do we want to predict?\n",
        "label_type = 'ner'\n",
        "\n",
        "# 3. make the label dictionary from the corpus\n",
        "label_dict = corpus.make_tag_dictionary('ner')\n",
        "\n",
        "# 4. initialize embedding stack with Flair and GloVe\n",
        "embedding_types = [\n",
        "    WordEmbeddings('glove'),\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "# 5. initialize sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)\n",
        "\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. start training\n",
        "trainer.train('/content/drive/MyDrive/hindi_ner/resources/taggers/sota-ner-flair',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKR-wNWZ8iec",
        "outputId": "e8d2bce1-cb7d-4997-e887-2633806813fd"
      },
      "source": [
        "from flair.embeddings import WordEmbeddings, StackedEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# 1. get the corpus\n",
        "print(corpus)\n",
        "\n",
        "# 2. what label do we want to predict?\n",
        "label_type = 'ner'\n",
        "\n",
        "# 3. make the label dictionary from the corpus\n",
        "label_dict = corpus.make_tag_dictionary(label_type)\n",
        "print(label_dict)\n",
        "\n",
        "# 4. initialize embeddings\n",
        "embedding_types = [\n",
        "\n",
        "    WordEmbeddings('glove'),\n",
        "\n",
        "    # comment in this line to use character embeddings\n",
        "    # CharacterEmbeddings(),\n",
        "\n",
        "    # comment in these lines to use flair embeddings\n",
        "    # FlairEmbeddings('news-forward'),\n",
        "    # FlairEmbeddings('news-backward'),\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "# 5. initialize sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type=label_type,\n",
        "                        use_crf=True)\n",
        "\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. start training\n",
        "trainer.train('resources/taggers/example-upos',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus: 15319 train + 5133 dev + 5053 test sentences\n",
            "Dictionary with 31 tags: O, NN, JJ, SYM, VM, VAUX, QC, NNP, CC, XC, PSP, DEM, QF, PRP, RP, RDP, NST, QO, RB, PSP:?, INTF, RP:?, NEG, WQ, INJ, CC:?, B-NP, RB:?, XCएंड, <START>\n",
            "2021-10-20 18:27:19,660 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:27:19,662 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=31, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-10-20 18:27:19,666 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:27:19,669 Corpus: \"Corpus: 15319 train + 5133 dev + 5053 test sentences\"\n",
            "2021-10-20 18:27:19,672 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:27:19,676 Parameters:\n",
            "2021-10-20 18:27:19,678  - learning_rate: \"0.1\"\n",
            "2021-10-20 18:27:19,680  - mini_batch_size: \"32\"\n",
            "2021-10-20 18:27:19,685  - patience: \"3\"\n",
            "2021-10-20 18:27:19,687  - anneal_factor: \"0.5\"\n",
            "2021-10-20 18:27:19,691  - max_epochs: \"10\"\n",
            "2021-10-20 18:27:19,693  - shuffle: \"True\"\n",
            "2021-10-20 18:27:19,697  - train_with_dev: \"False\"\n",
            "2021-10-20 18:27:19,699  - batch_growth_annealing: \"False\"\n",
            "2021-10-20 18:27:19,701 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:27:19,704 Model training base path: \"resources/taggers/example-upos\"\n",
            "2021-10-20 18:27:19,709 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:27:19,713 Device: cuda:0\n",
            "2021-10-20 18:27:19,716 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:27:19,720 Embeddings storage mode: cpu\n",
            "2021-10-20 18:27:19,723 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:27:27,532 epoch 1 - iter 47/479 - loss 2.12458420 - samples/sec: 193.66 - lr: 0.100000\n",
            "2021-10-20 18:27:35,129 epoch 1 - iter 94/479 - loss 1.79389152 - samples/sec: 198.13 - lr: 0.100000\n",
            "2021-10-20 18:27:42,775 epoch 1 - iter 141/479 - loss 1.63298074 - samples/sec: 197.05 - lr: 0.100000\n",
            "2021-10-20 18:27:51,020 epoch 1 - iter 188/479 - loss 1.53672712 - samples/sec: 182.57 - lr: 0.100000\n",
            "2021-10-20 18:27:58,849 epoch 1 - iter 235/479 - loss 1.46577835 - samples/sec: 192.26 - lr: 0.100000\n",
            "2021-10-20 18:28:06,555 epoch 1 - iter 282/479 - loss 1.41746353 - samples/sec: 195.37 - lr: 0.100000\n",
            "2021-10-20 18:28:15,973 epoch 1 - iter 329/479 - loss 1.38037946 - samples/sec: 159.81 - lr: 0.100000\n",
            "2021-10-20 18:28:23,758 epoch 1 - iter 376/479 - loss 1.35117483 - samples/sec: 193.34 - lr: 0.100000\n",
            "2021-10-20 18:28:31,456 epoch 1 - iter 423/479 - loss 1.32587231 - samples/sec: 195.55 - lr: 0.100000\n",
            "2021-10-20 18:28:39,361 epoch 1 - iter 470/479 - loss 1.30540250 - samples/sec: 190.42 - lr: 0.100000\n",
            "2021-10-20 18:28:40,796 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:28:40,798 EPOCH 1 done: loss 1.3023 - lr 0.1000000\n",
            "2021-10-20 18:32:47,403 DEV : loss 1.0455495119094849 - f1-score (micro avg)  0.5405\n",
            "2021-10-20 18:32:47,642 BAD EPOCHS (no improvement): 0\n",
            "2021-10-20 18:32:47,643 saving best model\n",
            "2021-10-20 18:32:50,859 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:32:58,895 epoch 2 - iter 47/479 - loss 1.09742700 - samples/sec: 187.43 - lr: 0.100000\n",
            "2021-10-20 18:33:05,703 epoch 2 - iter 94/479 - loss 1.08774911 - samples/sec: 221.19 - lr: 0.100000\n",
            "2021-10-20 18:33:12,551 epoch 2 - iter 141/479 - loss 1.08254557 - samples/sec: 219.87 - lr: 0.100000\n",
            "2021-10-20 18:33:19,393 epoch 2 - iter 188/479 - loss 1.07539423 - samples/sec: 220.04 - lr: 0.100000\n",
            "2021-10-20 18:33:26,385 epoch 2 - iter 235/479 - loss 1.06795144 - samples/sec: 215.35 - lr: 0.100000\n",
            "2021-10-20 18:33:33,377 epoch 2 - iter 282/479 - loss 1.06495676 - samples/sec: 215.45 - lr: 0.100000\n",
            "2021-10-20 18:33:40,552 epoch 2 - iter 329/479 - loss 1.06402358 - samples/sec: 209.80 - lr: 0.100000\n",
            "2021-10-20 18:33:47,984 epoch 2 - iter 376/479 - loss 1.06183771 - samples/sec: 202.64 - lr: 0.100000\n",
            "2021-10-20 18:33:54,832 epoch 2 - iter 423/479 - loss 1.05968187 - samples/sec: 219.86 - lr: 0.100000\n",
            "2021-10-20 18:34:01,663 epoch 2 - iter 470/479 - loss 1.05594888 - samples/sec: 220.40 - lr: 0.100000\n",
            "2021-10-20 18:34:03,258 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:34:03,260 EPOCH 2 done: loss 1.0559 - lr 0.1000000\n",
            "2021-10-20 18:38:30,159 DEV : loss 0.9705203771591187 - f1-score (micro avg)  0.6034\n",
            "2021-10-20 18:38:30,402 BAD EPOCHS (no improvement): 0\n",
            "2021-10-20 18:38:30,404 saving best model\n",
            "2021-10-20 18:38:33,379 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:38:40,832 epoch 3 - iter 47/479 - loss 1.03886071 - samples/sec: 202.05 - lr: 0.100000\n",
            "2021-10-20 18:38:47,966 epoch 3 - iter 94/479 - loss 1.02757497 - samples/sec: 211.07 - lr: 0.100000\n",
            "2021-10-20 18:38:55,242 epoch 3 - iter 141/479 - loss 1.02030790 - samples/sec: 206.88 - lr: 0.100000\n",
            "2021-10-20 18:39:02,383 epoch 3 - iter 188/479 - loss 1.02284176 - samples/sec: 210.84 - lr: 0.100000\n",
            "2021-10-20 18:39:09,240 epoch 3 - iter 235/479 - loss 1.02111389 - samples/sec: 219.65 - lr: 0.100000\n",
            "2021-10-20 18:39:16,176 epoch 3 - iter 282/479 - loss 1.01417096 - samples/sec: 217.05 - lr: 0.100000\n",
            "2021-10-20 18:39:23,771 epoch 3 - iter 329/479 - loss 1.01272547 - samples/sec: 198.25 - lr: 0.100000\n",
            "2021-10-20 18:39:30,872 epoch 3 - iter 376/479 - loss 1.00775877 - samples/sec: 212.12 - lr: 0.100000\n",
            "2021-10-20 18:39:38,023 epoch 3 - iter 423/479 - loss 1.00683148 - samples/sec: 210.53 - lr: 0.100000\n",
            "2021-10-20 18:39:44,797 epoch 3 - iter 470/479 - loss 1.00469697 - samples/sec: 222.42 - lr: 0.100000\n",
            "2021-10-20 18:39:46,165 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:39:46,167 EPOCH 3 done: loss 1.0043 - lr 0.1000000\n",
            "2021-10-20 18:44:23,322 DEV : loss 0.9489049315452576 - f1-score (micro avg)  0.5995\n",
            "2021-10-20 18:44:23,569 BAD EPOCHS (no improvement): 1\n",
            "2021-10-20 18:44:23,571 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:44:30,561 epoch 4 - iter 47/479 - loss 0.97661738 - samples/sec: 215.50 - lr: 0.100000\n",
            "2021-10-20 18:44:37,919 epoch 4 - iter 94/479 - loss 0.98304108 - samples/sec: 204.62 - lr: 0.100000\n",
            "2021-10-20 18:44:45,349 epoch 4 - iter 141/479 - loss 0.98918266 - samples/sec: 202.64 - lr: 0.100000\n",
            "2021-10-20 18:44:52,504 epoch 4 - iter 188/479 - loss 0.99162823 - samples/sec: 210.43 - lr: 0.100000\n",
            "2021-10-20 18:44:59,752 epoch 4 - iter 235/479 - loss 0.99149698 - samples/sec: 207.79 - lr: 0.100000\n",
            "2021-10-20 18:45:07,399 epoch 4 - iter 282/479 - loss 0.99152429 - samples/sec: 196.85 - lr: 0.100000\n",
            "2021-10-20 18:45:14,459 epoch 4 - iter 329/479 - loss 0.98892119 - samples/sec: 213.27 - lr: 0.100000\n",
            "2021-10-20 18:45:21,301 epoch 4 - iter 376/479 - loss 0.98665781 - samples/sec: 220.08 - lr: 0.100000\n",
            "2021-10-20 18:45:28,618 epoch 4 - iter 423/479 - loss 0.98291340 - samples/sec: 205.75 - lr: 0.100000\n",
            "2021-10-20 18:45:35,835 epoch 4 - iter 470/479 - loss 0.98143508 - samples/sec: 208.63 - lr: 0.100000\n",
            "2021-10-20 18:45:37,213 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:45:37,218 EPOCH 4 done: loss 0.9812 - lr 0.1000000\n",
            "2021-10-20 18:50:12,437 DEV : loss 0.9226442575454712 - f1-score (micro avg)  0.6251\n",
            "2021-10-20 18:50:12,671 BAD EPOCHS (no improvement): 0\n",
            "2021-10-20 18:50:12,674 saving best model\n",
            "2021-10-20 18:50:15,570 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:50:22,767 epoch 5 - iter 47/479 - loss 0.97589668 - samples/sec: 209.23 - lr: 0.100000\n",
            "2021-10-20 18:50:30,258 epoch 5 - iter 94/479 - loss 0.96921538 - samples/sec: 201.10 - lr: 0.100000\n",
            "2021-10-20 18:50:37,681 epoch 5 - iter 141/479 - loss 0.97770106 - samples/sec: 202.79 - lr: 0.100000\n",
            "2021-10-20 18:50:44,977 epoch 5 - iter 188/479 - loss 0.97337141 - samples/sec: 206.34 - lr: 0.100000\n",
            "2021-10-20 18:50:52,024 epoch 5 - iter 235/479 - loss 0.96686240 - samples/sec: 213.73 - lr: 0.100000\n",
            "2021-10-20 18:50:58,902 epoch 5 - iter 282/479 - loss 0.96816437 - samples/sec: 219.06 - lr: 0.100000\n",
            "2021-10-20 18:51:06,381 epoch 5 - iter 329/479 - loss 0.97024619 - samples/sec: 201.28 - lr: 0.100000\n",
            "2021-10-20 18:51:13,392 epoch 5 - iter 376/479 - loss 0.96831463 - samples/sec: 214.73 - lr: 0.100000\n",
            "2021-10-20 18:51:20,341 epoch 5 - iter 423/479 - loss 0.96593692 - samples/sec: 216.69 - lr: 0.100000\n",
            "2021-10-20 18:51:27,366 epoch 5 - iter 470/479 - loss 0.96236044 - samples/sec: 214.34 - lr: 0.100000\n",
            "2021-10-20 18:51:28,636 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:51:28,639 EPOCH 5 done: loss 0.9626 - lr 0.1000000\n",
            "2021-10-20 18:56:01,580 DEV : loss 0.9035009145736694 - f1-score (micro avg)  0.6149\n",
            "2021-10-20 18:56:01,832 BAD EPOCHS (no improvement): 1\n",
            "2021-10-20 18:56:01,835 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:56:09,387 epoch 6 - iter 47/479 - loss 0.96929287 - samples/sec: 199.48 - lr: 0.100000\n",
            "2021-10-20 18:56:16,582 epoch 6 - iter 94/479 - loss 0.96674040 - samples/sec: 209.24 - lr: 0.100000\n",
            "2021-10-20 18:56:23,553 epoch 6 - iter 141/479 - loss 0.95622174 - samples/sec: 215.98 - lr: 0.100000\n",
            "2021-10-20 18:56:30,356 epoch 6 - iter 188/479 - loss 0.95367107 - samples/sec: 221.46 - lr: 0.100000\n",
            "2021-10-20 18:56:37,406 epoch 6 - iter 235/479 - loss 0.95234840 - samples/sec: 213.53 - lr: 0.100000\n",
            "2021-10-20 18:56:44,431 epoch 6 - iter 282/479 - loss 0.95281582 - samples/sec: 214.36 - lr: 0.100000\n",
            "2021-10-20 18:56:51,479 epoch 6 - iter 329/479 - loss 0.95482124 - samples/sec: 213.64 - lr: 0.100000\n",
            "2021-10-20 18:56:58,834 epoch 6 - iter 376/479 - loss 0.95070976 - samples/sec: 204.70 - lr: 0.100000\n",
            "2021-10-20 18:57:06,088 epoch 6 - iter 423/479 - loss 0.95103815 - samples/sec: 207.64 - lr: 0.100000\n",
            "2021-10-20 18:57:13,025 epoch 6 - iter 470/479 - loss 0.94998032 - samples/sec: 217.02 - lr: 0.100000\n",
            "2021-10-20 18:57:14,267 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 18:57:14,269 EPOCH 6 done: loss 0.9496 - lr 0.1000000\n",
            "2021-10-20 19:01:46,677 DEV : loss 0.8905189633369446 - f1-score (micro avg)  0.6291\n",
            "2021-10-20 19:01:46,916 BAD EPOCHS (no improvement): 0\n",
            "2021-10-20 19:01:46,918 saving best model\n",
            "2021-10-20 19:01:49,798 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 19:01:56,944 epoch 7 - iter 47/479 - loss 0.94317474 - samples/sec: 210.84 - lr: 0.100000\n",
            "2021-10-20 19:02:04,802 epoch 7 - iter 94/479 - loss 0.94330201 - samples/sec: 191.58 - lr: 0.100000\n",
            "2021-10-20 19:02:11,928 epoch 7 - iter 141/479 - loss 0.94524936 - samples/sec: 211.35 - lr: 0.100000\n",
            "2021-10-20 19:02:18,832 epoch 7 - iter 188/479 - loss 0.94502817 - samples/sec: 218.05 - lr: 0.100000\n",
            "2021-10-20 19:02:25,581 epoch 7 - iter 235/479 - loss 0.94433124 - samples/sec: 223.18 - lr: 0.100000\n",
            "2021-10-20 19:02:32,718 epoch 7 - iter 282/479 - loss 0.94336730 - samples/sec: 210.97 - lr: 0.100000\n",
            "2021-10-20 19:02:39,566 epoch 7 - iter 329/479 - loss 0.94203042 - samples/sec: 219.87 - lr: 0.100000\n",
            "2021-10-20 19:02:46,320 epoch 7 - iter 376/479 - loss 0.94163282 - samples/sec: 222.96 - lr: 0.100000\n",
            "2021-10-20 19:02:53,340 epoch 7 - iter 423/479 - loss 0.94058640 - samples/sec: 214.47 - lr: 0.100000\n",
            "2021-10-20 19:03:00,386 epoch 7 - iter 470/479 - loss 0.93944265 - samples/sec: 213.77 - lr: 0.100000\n",
            "2021-10-20 19:03:01,718 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 19:03:01,720 EPOCH 7 done: loss 0.9393 - lr 0.1000000\n",
            "2021-10-20 19:07:37,302 DEV : loss 0.8884903788566589 - f1-score (micro avg)  0.6254\n",
            "2021-10-20 19:07:37,541 BAD EPOCHS (no improvement): 1\n",
            "2021-10-20 19:07:37,543 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 19:07:44,814 epoch 8 - iter 47/479 - loss 0.92664970 - samples/sec: 207.21 - lr: 0.100000\n",
            "2021-10-20 19:07:51,677 epoch 8 - iter 94/479 - loss 0.92424759 - samples/sec: 219.39 - lr: 0.100000\n",
            "2021-10-20 19:07:58,916 epoch 8 - iter 141/479 - loss 0.92752395 - samples/sec: 208.12 - lr: 0.100000\n",
            "2021-10-20 19:08:06,260 epoch 8 - iter 188/479 - loss 0.93182829 - samples/sec: 204.99 - lr: 0.100000\n",
            "2021-10-20 19:08:13,605 epoch 8 - iter 235/479 - loss 0.93369446 - samples/sec: 205.04 - lr: 0.100000\n",
            "2021-10-20 19:08:20,769 epoch 8 - iter 282/479 - loss 0.93475439 - samples/sec: 210.13 - lr: 0.100000\n",
            "2021-10-20 19:08:27,659 epoch 8 - iter 329/479 - loss 0.93506798 - samples/sec: 218.51 - lr: 0.100000\n",
            "2021-10-20 19:08:34,876 epoch 8 - iter 376/479 - loss 0.93423079 - samples/sec: 208.82 - lr: 0.100000\n",
            "2021-10-20 19:08:42,587 epoch 8 - iter 423/479 - loss 0.93194856 - samples/sec: 195.26 - lr: 0.100000\n",
            "2021-10-20 19:08:49,972 epoch 8 - iter 470/479 - loss 0.93169445 - samples/sec: 203.91 - lr: 0.100000\n",
            "2021-10-20 19:08:51,316 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 19:08:51,318 EPOCH 8 done: loss 0.9314 - lr 0.1000000\n",
            "2021-10-20 19:13:31,320 DEV : loss 0.884803831577301 - f1-score (micro avg)  0.6391\n",
            "2021-10-20 19:13:31,562 BAD EPOCHS (no improvement): 0\n",
            "2021-10-20 19:13:31,565 saving best model\n",
            "2021-10-20 19:13:34,355 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 19:13:41,398 epoch 9 - iter 47/479 - loss 0.93608651 - samples/sec: 213.93 - lr: 0.100000\n",
            "2021-10-20 19:13:48,503 epoch 9 - iter 94/479 - loss 0.93128244 - samples/sec: 211.87 - lr: 0.100000\n",
            "2021-10-20 19:13:56,023 epoch 9 - iter 141/479 - loss 0.93229832 - samples/sec: 200.22 - lr: 0.100000\n",
            "2021-10-20 19:14:02,618 epoch 9 - iter 188/479 - loss 0.93117561 - samples/sec: 228.24 - lr: 0.100000\n",
            "2021-10-20 19:14:09,497 epoch 9 - iter 235/479 - loss 0.92606809 - samples/sec: 218.85 - lr: 0.100000\n",
            "2021-10-20 19:14:16,367 epoch 9 - iter 282/479 - loss 0.92394972 - samples/sec: 219.12 - lr: 0.100000\n",
            "2021-10-20 19:14:23,138 epoch 9 - iter 329/479 - loss 0.92200917 - samples/sec: 222.31 - lr: 0.100000\n",
            "2021-10-20 19:14:30,534 epoch 9 - iter 376/479 - loss 0.92321509 - samples/sec: 203.55 - lr: 0.100000\n",
            "2021-10-20 19:14:37,467 epoch 9 - iter 423/479 - loss 0.92150728 - samples/sec: 217.14 - lr: 0.100000\n",
            "2021-10-20 19:14:44,699 epoch 9 - iter 470/479 - loss 0.92403288 - samples/sec: 208.16 - lr: 0.100000\n",
            "2021-10-20 19:14:45,966 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 19:14:45,967 EPOCH 9 done: loss 0.9240 - lr 0.1000000\n",
            "2021-10-20 19:19:18,289 DEV : loss 0.87498539686203 - f1-score (micro avg)  0.6275\n",
            "2021-10-20 19:19:18,543 BAD EPOCHS (no improvement): 1\n",
            "2021-10-20 19:19:18,545 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 19:19:25,431 epoch 10 - iter 47/479 - loss 0.92984066 - samples/sec: 218.85 - lr: 0.100000\n",
            "2021-10-20 19:19:32,181 epoch 10 - iter 94/479 - loss 0.91553394 - samples/sec: 223.03 - lr: 0.100000\n",
            "2021-10-20 19:19:39,091 epoch 10 - iter 141/479 - loss 0.91757672 - samples/sec: 217.87 - lr: 0.100000\n",
            "2021-10-20 19:19:46,612 epoch 10 - iter 188/479 - loss 0.91063747 - samples/sec: 200.14 - lr: 0.100000\n",
            "2021-10-20 19:19:53,557 epoch 10 - iter 235/479 - loss 0.91391074 - samples/sec: 216.78 - lr: 0.100000\n",
            "2021-10-20 19:20:00,236 epoch 10 - iter 282/479 - loss 0.91371250 - samples/sec: 225.39 - lr: 0.100000\n",
            "2021-10-20 19:20:07,239 epoch 10 - iter 329/479 - loss 0.91730049 - samples/sec: 215.00 - lr: 0.100000\n",
            "2021-10-20 19:20:14,308 epoch 10 - iter 376/479 - loss 0.91562423 - samples/sec: 212.99 - lr: 0.100000\n",
            "2021-10-20 19:20:21,525 epoch 10 - iter 423/479 - loss 0.91553164 - samples/sec: 208.60 - lr: 0.100000\n",
            "2021-10-20 19:20:28,533 epoch 10 - iter 470/479 - loss 0.91555885 - samples/sec: 214.83 - lr: 0.100000\n",
            "2021-10-20 19:20:29,812 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 19:20:29,814 EPOCH 10 done: loss 0.9154 - lr 0.1000000\n",
            "2021-10-20 19:25:03,868 DEV : loss 0.8667994141578674 - f1-score (micro avg)  0.6403\n",
            "2021-10-20 19:25:04,099 BAD EPOCHS (no improvement): 0\n",
            "2021-10-20 19:25:04,103 saving best model\n",
            "2021-10-20 19:25:09,770 ----------------------------------------------------------------------------------------------------\n",
            "2021-10-20 19:25:09,772 loading file resources/taggers/example-upos/best-model.pt\n",
            "2021-10-20 19:29:09,416 0.6339\t0.6339\t0.6339\t0.6339\n",
            "2021-10-20 19:29:09,418 \n",
            "Results:\n",
            "- F-score (micro) 0.6339\n",
            "- F-score (macro) 0.2767\n",
            "- Accuracy 0.6339\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          NN     0.6416    0.6383    0.6400     23630\n",
            "         PSP     0.8887    0.9025    0.8955     16516\n",
            "          JJ     0.3783    0.4507    0.4114      8941\n",
            "         SYM     0.9981    0.9881    0.9931      9486\n",
            "          XC     0.3368    0.4458    0.3837      6795\n",
            "          VM     0.5462    0.5075    0.5261      7937\n",
            "         NNP     0.5689    0.4225    0.4849      6746\n",
            "        VAUX     0.4259    0.7185    0.5348      3819\n",
            "          QC     0.8275    0.7892    0.8079      4977\n",
            "         PRP     0.3695    0.2856    0.3222      3134\n",
            "          CC     0.7157    0.5860    0.6444      2307\n",
            "         DEM     0.1903    0.2741    0.2246       872\n",
            "          RP     0.8889    0.0080    0.0158      1001\n",
            "         NST     0.2903    0.0218    0.0405       827\n",
            "          QF     0.9000    0.0322    0.0622       559\n",
            "          RB     0.3485    0.0846    0.1361       272\n",
            "          QO     0.5814    0.1152    0.1923       217\n",
            "        INTF     0.0000    0.0000    0.0000       234\n",
            "         NEG     0.0000    0.0000    0.0000       152\n",
            "         RDP     0.4167    0.0820    0.1370       122\n",
            "       PSP:?     0.5000    0.0094    0.0185       106\n",
            "          WQ     0.0000    0.0000    0.0000        20\n",
            "        RP:?     0.0000    0.0000    0.0000        11\n",
            "          NP     0.0000    0.0000    0.0000         2\n",
            "       XCएंड     0.0000    0.0000    0.0000         1\n",
            "        RB:?     0.0000    0.0000    0.0000         1\n",
            "        CC:?     0.0000    0.0000    0.0000         1\n",
            "\n",
            "   micro avg     0.6339    0.6339    0.6339     98686\n",
            "   macro avg     0.4005    0.2727    0.2767     98686\n",
            "weighted avg     0.6468    0.6339    0.6283     98686\n",
            " samples avg     0.6339    0.6339    0.6339     98686\n",
            "\n",
            "2021-10-20 19:29:09,425 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(1.0455, device='cuda:0'),\n",
              "  tensor(0.9705, device='cuda:0'),\n",
              "  tensor(0.9489, device='cuda:0'),\n",
              "  tensor(0.9226, device='cuda:0'),\n",
              "  tensor(0.9035, device='cuda:0'),\n",
              "  tensor(0.8905, device='cuda:0'),\n",
              "  tensor(0.8885, device='cuda:0'),\n",
              "  tensor(0.8848, device='cuda:0'),\n",
              "  tensor(0.8750, device='cuda:0'),\n",
              "  tensor(0.8668, device='cuda:0')],\n",
              " 'dev_score_history': [0.5404630427073307,\n",
              "  0.6034044277825624,\n",
              "  0.5994731242717463,\n",
              "  0.6251177871219413,\n",
              "  0.6148538426465373,\n",
              "  0.6290896195349308,\n",
              "  0.6254318861137849,\n",
              "  0.6391103905972947,\n",
              "  0.6275292568012564,\n",
              "  0.6403059932114089],\n",
              " 'test_score': 0.6339298380722697,\n",
              " 'train_loss_history': [1.3022668868658953,\n",
              "  1.0559345146415335,\n",
              "  1.0042648291463083,\n",
              "  0.9812139950902015,\n",
              "  0.9625689427746995,\n",
              "  0.9496405160396773,\n",
              "  0.9393250202575422,\n",
              "  0.9313503229443839,\n",
              "  0.9239784753891446,\n",
              "  0.9154484358986804]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7ofyj7aDb3H",
        "outputId": "cbb01e8d-05a2-445b-b452-545c17c91f99"
      },
      "source": [
        "from flair.models import SequenceTagger\n",
        "from flair.data import Sentence\n",
        "\n",
        "# load the model you trained\n",
        "model = SequenceTagger.load('resources/taggers/example-upos/final-model.pt')\n",
        "\n",
        "# create example sentence\n",
        "sentence = Sentence('मिर्ज़ा असद - उल्लाह बेग ख़ां उर्फ ग़ालिब २७ दिसंबर १७९६-१५ फरवरी १८६९ उर्दू एवं फ़ारसी भाषा के महान शायर थे.')\n",
        "\n",
        "# predict tags and print\n",
        "model.predict(sentence)\n",
        "\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-20 19:34:38,277 loading file resources/taggers/example-upos/final-model.pt\n",
            "मिर्ज़ा <XC> असद <XC> - <SYM> उल्लाह <XC> बेग <XC> ख़ां <XC> उर्फ <XC> ग़ालिब <NNP> २७ <QC> दिसंबर <XC> १७९६-१५ <XC> फरवरी <NNP> १८६९ <QC> उर्दू <PSP> एवं <JJ> फ़ारसी <NN> भाषा <NN> के <PSP> महान <JJ> शायर <NN> थे <VM> . <SYM>\n"
          ]
        }
      ]
    }
  ]
}