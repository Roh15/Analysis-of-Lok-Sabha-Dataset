{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Calculate Stats.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1U8jX4zOYJOSJd1L7ojlqBhS_ckFVUCnJ",
      "authorship_tag": "ABX9TyP3Vwd5GU/WuVoIQ3vSr9k9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roh15/Analysis-of-Lok-Sabha-Dataset/blob/main/Calculate_Stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhiVTyISTTSs"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import regex as re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIddKn4s_V3W"
      },
      "source": [
        "def countFiles():\n",
        "  file_count = dict.fromkeys(list(range(1,18)), 0)\n",
        "  for ls in range(1,18):\n",
        "    files = 0\n",
        "    for file in range(1,1000):\n",
        "      filepath = '/content/drive/MyDrive/Lok Sabha Data/textfiles/' + str(ls) + '/' + str(file) + '.csv'\n",
        "      if os.path.isfile(filepath):\n",
        "        files += 1\n",
        "    file_count[ls] = files\n",
        "  return file_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7EBMn3DAKLA"
      },
      "source": [
        "num_files = countFiles()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpUedDH3SDNR"
      },
      "source": [
        "def remainingNERfiles(ls):\n",
        "  not_done = []\n",
        "  for file in range(1,num_files[ls]):\n",
        "    filepath = '/content/drive/MyDrive/Lok Sabha Data/NER/' + str(ls) + '/' + str(file) + '_NER.csv'\n",
        "    if not os.path.isfile(filepath):\n",
        "      not_done.append(file)\n",
        "  print('LS-' + str(ls) + ' remainig NER files are: ' + str(not_done))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhfz0_r2oEDH"
      },
      "source": [
        "def remainingPOSfiles(ls):\n",
        "  not_done = []\n",
        "  for file in range(1,num_files[ls]):\n",
        "    filepath = '/content/drive/MyDrive/Lok Sabha Data/POS/' + str(ls) + '/' + str(file) + '_POS.csv'\n",
        "    if not os.path.isfile(filepath):\n",
        "      not_done.append(file)\n",
        "  print('LS-' + str(ls) + ' remainig POS files are: ' + str(not_done))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfZ_OcpAT3DJ"
      },
      "source": [
        "for i in range(16,17):\n",
        "  remainingNERfiles(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieZiyl_eoKj1"
      },
      "source": [
        "remainingPOSfiles(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSty9riOWLk2"
      },
      "source": [
        "entities = [\n",
        "  'PERSON',\n",
        "  'NORP',\n",
        "  'FAC',\n",
        "  'ORG',\n",
        "  'GPE',\n",
        "  'LOC',\n",
        "  'PRODUCT',\n",
        "  'EVENT',\n",
        "  'WORK_OF_ART',\n",
        "  'LAW',\n",
        "  'LANGUAGE',\n",
        "  'DATE',\n",
        "  'TIME',\n",
        "  'PERCENT',\n",
        "  'MONEY',\n",
        "  'QUANTITY',\n",
        "  'ORDINAL',\n",
        "  'CARDINAL']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fTQkeOumTOI"
      },
      "source": [
        "ls_entity_counts = dict.fromkeys(list(range(1,18)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efCQ2fLbkXpi"
      },
      "source": [
        "def countEntities(ls):\n",
        "  ls_entities = dict.fromkeys(entities, 0)\n",
        "  for file in range(1,num_files[ls]):\n",
        "    filepath = '/content/drive/MyDrive/Lok Sabha Data/NER/' + str(ls) + '/' + str(file) + '_NER.csv'\n",
        "    try:\n",
        "      nerfile = pd.read_csv(filepath, usecols=['entity_type'],lineterminator='\\n')\n",
        "      entity_list = nerfile['entity_type'].values\n",
        "      for entity in entity_list:\n",
        "        ls_entities[entity] += 1\n",
        "    except FileNotFoundError as e:\n",
        "      continue\n",
        "  ls_entity_counts[ls] = ls_entities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cKDvB0zmRiz"
      },
      "source": [
        "for i in [8,15,16,17]:\n",
        "  countEntities(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX6mw4oK7sXI"
      },
      "source": [
        "tags = [\n",
        "  'NOUN',\n",
        "  'PROPN']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZcbQN8g7510"
      },
      "source": [
        "def countPOSTags(ls):\n",
        "  ls_tags = dict.fromkeys(tags, 0)\n",
        "  for file in range(1,num_files[ls]):\n",
        "    filepath = '/content/drive/MyDrive/Lok Sabha Data/POS/' + str(ls) + '/' + str(file) + '_POS.csv'\n",
        "    try:\n",
        "      posfile = pd.read_csv(filepath, usecols=['word_upos'],lineterminator='\\n')\n",
        "      tag_list = posfile['word_upos'].values\n",
        "      for tag in tag_list:\n",
        "        try:\n",
        "          ls_tags[tag] += 1\n",
        "        except KeyError as e:\n",
        "          continue\n",
        "    except FileNotFoundError as e:\n",
        "      continue\n",
        "  print(ls_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op4InGJk8c0V"
      },
      "source": [
        "countPOSTags(16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYGgpGvx3r5t"
      },
      "source": [
        "ls = 14\n",
        "file = 1\n",
        "filepath = '/content/drive/MyDrive/Lok Sabha Data/NER/' + str(ls) + '/' + str(file) + '_NER.csv'\n",
        "nerfile = pd.read_csv(filepath, usecols=['entity_text', 'entity_type'])\n",
        "nerfile.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXQkJmZ2zrTh"
      },
      "source": [
        "def maxFrequency(my_list):\n",
        "    # Creating an empty dictionary\n",
        "    freq = {}\n",
        "    for items in my_list:\n",
        "        freq[items] = my_list.count(items)\n",
        "  \n",
        "    freq_max = dict(sorted(freq.items(), key=lambda item: item[1], reverse=True))\n",
        "    count = 0\n",
        "    for key, value in freq_max.items():\n",
        "        print (\"% s : % d\"%(key, value))\n",
        "        count+=1\n",
        "        if count == 3:\n",
        "          break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_CVOmvT1Zhn"
      },
      "source": [
        "for entity in entities:\n",
        "  instances = []\n",
        "  print(' ')\n",
        "  print(entity)\n",
        "  for i in range(len(nerfile)):\n",
        "    if nerfile.loc[i]['entity_type'] == entity:\n",
        "      instances.append(nerfile.loc[i]['entity_text'])\n",
        "  maxFrequency(instances)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzDohQsH3oYj"
      },
      "source": [
        "# make a stat file listing all entities frequencies\n",
        "\n",
        "entity_counter = []\n",
        "ls = 16\n",
        "already_encountered = []\n",
        "for file in tqdm(range(1,\n",
        "                       #num_files[ls]\n",
        "                       332)):\n",
        "  filepath = '/content/drive/MyDrive/Lok Sabha Data/NER/' + str(ls) + '/' + str(file) + '_NER.csv'\n",
        "  try:\n",
        "    ner_file = pd.read_csv(filepath, lineterminator='\\n')\n",
        "    for index, row in ner_file.iterrows():\n",
        "      try:\n",
        "        match = re.search('\\p{Devanagari}', row['entity_text'])\n",
        "      except:\n",
        "        continue\n",
        "      if match == None:\n",
        "        try:\n",
        "          i = already_encountered.index(row['entity_text'])\n",
        "          entity_counter[i][2] += 1\n",
        "        except ValueError as e:\n",
        "          entity_counter.append([row['entity_text'], row['entity_type'], 1])\n",
        "          already_encountered.append(row['entity_text'])\n",
        "  except FileNotFoundError as e:\n",
        "    print(str(file) + 'not found')\n",
        "    continue\n",
        "\n",
        "statfilepath = '/content/drive/MyDrive/Lok Sabha Data/LS16_NER_Stats.csv'\n",
        "pd.DataFrame(entity_counter, columns=['entity_text', 'entity_type', 'instances']).to_csv(statfilepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--DwFaBMCEEw"
      },
      "source": [
        "# make a stat file listing all noun frequencies\n",
        "\n",
        "noun_counter = []\n",
        "ls = 16\n",
        "already_encountered = []\n",
        "for file in tqdm(range(1,\n",
        "                       #num_files[ls]\n",
        "                       332)):\n",
        "  filepath = '/content/drive/MyDrive/Lok Sabha Data/Hindi+English POS-NER/' + str(ls) + '/' + str(file) + '_POS-NER.csv'\n",
        "  try:\n",
        "    pos_file = pd.read_csv(filepath, lineterminator='\\n')\n",
        "    for index, row in pos_file.iterrows():\n",
        "      if row['word_upos'] == 'NOUN' or row['word_upos'] == 'PROPN':\n",
        "        try:\n",
        "          i = already_encountered.index(row['word/entity'])\n",
        "          noun_counter[i][3] += 1\n",
        "        except ValueError as e:\n",
        "          noun_counter.append([row['word/entity'], row['word_upos'], row['word_xpos'], 1])\n",
        "          already_encountered.append(row['word/entity'])\n",
        "  except FileNotFoundError as e:\n",
        "      continue\n",
        "\n",
        "statfilepath = '/content/drive/MyDrive/Lok Sabha Data/LS16_Noun_Stats.csv'\n",
        "pd.DataFrame(noun_counter, columns=['word', 'upos', 'xpos', 'instances']).to_csv(statfilepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dc-rxq-Payt"
      },
      "source": [
        "# filter prop nouns\n",
        "\n",
        "arr = []\n",
        "filepath = '/content/drive/MyDrive/Lok Sabha Data/LS16_Noun_Stats.csv'\n",
        "target_file = pd.read_csv(filepath, lineterminator='\\n')\n",
        "for index, row in target_file.iterrows():\n",
        "  if row['upos'] == 'NOUN':\n",
        "    try:\n",
        "      match = re.search('\\p{Devanagari}', row['word'])\n",
        "    except:\n",
        "      continue\n",
        "    if match == None:\n",
        "      continue\n",
        "    else:\n",
        "      arr.append([row['word'], row['instances']])\n",
        "\n",
        "statfilepath = '/content/drive/MyDrive/Lok Sabha Data/LS16_PropN.csv'\n",
        "pd.DataFrame(arr, columns=['word', 'instances']).to_csv(statfilepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBhqBDT4Zby2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}